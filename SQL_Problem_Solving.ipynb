{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkbglRJ3wx05mX5aDBdSWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcbzmani/SQL_Learning/blob/main/SQL_Problem_Solving.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld4m7AaBS8oI",
        "outputId": "d5f4be2d-0738-4986-dd54-75f94eb04560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install delta-spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFwT8T-kZ8in",
        "outputId": "5b9fecc7-612e-46ed-a8f1-1a1a15e4ac6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting delta-spark\n",
            "  Downloading delta_spark-2.1.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from delta-spark) (4.13.0)\n",
            "Requirement already satisfied: pyspark<3.4.0,>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from delta-spark) (3.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (4.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark<3.4.0,>=3.3.0->delta-spark) (0.10.9.5)\n",
            "Installing collected packages: delta-spark\n",
            "Successfully installed delta-spark-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from delta import *\n",
        "builder= SparkSession.builder.appName('Deltalake')\\\n",
        "         .config('spark.sql.extensions','io.delta.sql.DeltaSparkSessionExtension')\\\n",
        "         .config('spark.sql.catalog.spark_catlog','org.apache.spark.sql.delta.catalog.DeltaCatalog')\\\n",
        "         .config('spark.jars.packages','io.delta:delta-core_2.12:2.0.0')  "
      ],
      "metadata": {
        "id": "HygO7AguS_bZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
      ],
      "metadata": {
        "id": "3kcpe-FnZ2uS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Team Winning Percentage**\n",
        "**Get Team winning percentage. You have given with the data of Matches, and winning team from this we need to derive Winning Percantage of each team**"
      ],
      "metadata": {
        "id": "yI8xnfhnbgq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [('IND','SA','IND'),('SA','IND','SA'),('IND','PAK','IND'),('AUS','PAK','AUS'),('SL','AUS','AUS')]\n",
        "df = spark.createDataFrame(data,['Team1','Team2','Winning_Team'])"
      ],
      "metadata": {
        "id": "1rRwJQqbZ_n2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView('teamsstats')"
      ],
      "metadata": {
        "id": "JgqGy_2JaYyL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cpD-uTabir",
        "outputId": "fbdb32d2-0f03-4f8a-98f5-77552c80486b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+------------+\n",
            "|Team1|Team2|Winning_Team|\n",
            "+-----+-----+------------+\n",
            "|  IND|   SA|         IND|\n",
            "|   SA|  IND|          SA|\n",
            "|  IND|  PAK|         IND|\n",
            "|  AUS|  PAK|         AUS|\n",
            "|   SL|  AUS|         AUS|\n",
            "+-----+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = spark.sql(\"\"\"\n",
        "with \n",
        "wining_list as (\n",
        "  select \n",
        "    Winning_Team,\n",
        "    count(*) as wincount \n",
        "  from teamsstats \n",
        "    group by Winning_Team),\n",
        "team_play_cnt as (\n",
        "  select team,\n",
        "          count(*) as totplay \n",
        "      from ( select \n",
        "                    Team1 as team \n",
        "              from teamsstats \n",
        "                union all \n",
        "           select \n",
        "                  Team2 as team \n",
        "           from teamsstats ) a \n",
        "           group by a.team)\n",
        "\n",
        "select \n",
        "    team, \n",
        "    round(coalesce(wincount,0)/totplay,2)*100 as win_percent \n",
        "from  team_play_cnt\n",
        "left join  wining_list  \n",
        "on team_play_cnt.team = wining_list.Winning_Team\n",
        "order by round(coalesce(wincount,0)/totplay,2)*100 desc\"\"\")"
      ],
      "metadata": {
        "id": "3CupA9FKabHE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiTtqsryaf-B",
        "outputId": "5489396e-d9d5-4076-d8a5-4230c2817051"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+\n",
            "|team|win_percent|\n",
            "+----+-----------+\n",
            "| AUS|      100.0|\n",
            "| IND|       67.0|\n",
            "|  SA|       50.0|\n",
            "|  SL|        0.0|\n",
            "| PAK|        0.0|\n",
            "+----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Count of Passengers in Bus** \n",
        " \n",
        " We need to idenify how many passengers boarded on a particular bus\n",
        "\n",
        " Expected result for below one is \n",
        "        10 -> 0\n",
        "        20 -> 1\n",
        "        21 -> 3\n",
        "        22 -> 1\n",
        "        30 -> 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KSFeOK2UcD38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bus_data = [(10,'W','B','10:55'),(20,'B','P','06:20'),(21,'B','P','14:00'),(22,'B','P','21:40'),(30,'P','M','13:30')]\n",
        "bus_col = ['ID','Origin','Destn','Time']\n",
        "pass_data = [(1,'P','M','13:30'),(2,'P','M','13:31'),(10,'W','P','10:00'),(11,'W','B','22:31'),(40,'B','P','06:15'),(41,'B','P','06:50'),\\\n",
        "            (42,'B','P','07:12'),(43,'B','P','12:03'),(44,'B','P','20:00') ]\n",
        "pass_col = ['id','Origin','Destn','time']"
      ],
      "metadata": {
        "id": "SM02du8XcBrm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bus_df = spark.createDataFrame(bus_data,bus_col)\n",
        "bus_df.createOrReplaceTempView('bus')\n",
        "pass_df = spark.createDataFrame(pass_data,pass_col)\n",
        "pass_df.createOrReplaceTempView('passenger')"
      ],
      "metadata": {
        "id": "QddPfTAAebao"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bus_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnuhk3IsfTR0",
        "outputId": "34617627-09d3-4f26-92a3-02c548d11d4d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+-----+-----+\n",
            "| ID|Origin|Destn| Time|\n",
            "+---+------+-----+-----+\n",
            "| 10|     W|    B|10:55|\n",
            "| 20|     B|    P|06:20|\n",
            "| 21|     B|    P|14:00|\n",
            "| 22|     B|    P|21:40|\n",
            "| 30|     P|    M|13:30|\n",
            "+---+------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pass_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmWrPZpgfYlW",
        "outputId": "2e0cfca9-6efd-4573-be00-4a73e8e8cb5c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+-----+-----+\n",
            "| id|Origin|Destn| time|\n",
            "+---+------+-----+-----+\n",
            "|  1|     P|    M|13:30|\n",
            "|  2|     P|    M|13:31|\n",
            "| 10|     W|    P|10:00|\n",
            "| 11|     W|    B|22:31|\n",
            "| 40|     B|    P|06:15|\n",
            "| 41|     B|    P|06:50|\n",
            "| 42|     B|    P|07:12|\n",
            "| 43|     B|    P|12:03|\n",
            "| 44|     B|    P|20:00|\n",
            "+---+------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.sql(\"\"\"\n",
        "with \n",
        "bus_prev_time as(\n",
        "    select ID, Origin,Destn,coalesce(prevtime,'00:00') as prev_time,Time from (\n",
        "    select ID, Origin,Destn, Time, lag(Time) over(partition by Origin,Destn order by Time asc) as prevtime from bus) a\n",
        "),\n",
        "passenger as (\n",
        "    select Origin,Destn, time from passenger\n",
        ")\n",
        "\n",
        "select a.ID, sum(a.passcount) from (\n",
        "select b.ID,\n",
        "      case when p.time is null \n",
        "            then 0\n",
        "      else 1 end as passcount \n",
        "from bus_prev_time b\n",
        "left join passenger p\n",
        "on b.Origin = p.Origin\n",
        "and b.Destn = p.Destn\n",
        "and p.time between b.prev_time and b.Time ) a \n",
        "group by a.ID\n",
        "order by a.ID\"\"\")"
      ],
      "metadata": {
        "id": "6SLDv_G2gQT2"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxhtJCAggjQx",
        "outputId": "4b156d42-3c99-4a32-c16b-62e0854d10a0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------+\n",
            "| ID|sum(passcount)|\n",
            "+---+--------------+\n",
            "| 10|             0|\n",
            "| 20|             1|\n",
            "| 21|             3|\n",
            "| 22|             1|\n",
            "| 30|             1|\n",
            "+---+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Total balance of a customer**\n",
        "\n",
        "You are given with transaction details of payment app. You need to identify the total balance of each customer"
      ],
      "metadata": {
        "id": "evTPedyWl6n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transaction_data = [(1,'AA','BA',120.22),(2,'BA','CA',100.55),(3,'AA','CA',250.22),(4,'CA','AA',34.55),(5,'CA','BA',55.55),(6,'ZA','AA',450.33),\\\n",
        "                    (7,'DA','ZA',456.55),(8,'BA','ZA',55.78)]\n",
        "trans_schema = ['trans_id','sender','receiver','amount']\n",
        "trans_df = spark.createDataFrame(transaction_data,trans_schema)"
      ],
      "metadata": {
        "id": "6zbCMkX3i4Y4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_df.createOrReplaceTempView('trans')"
      ],
      "metadata": {
        "id": "CYWEjV2dnj1U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vsV52YgnDTK",
        "outputId": "3f4b8c6c-44d0-4410-f24b-f75777c1f365"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------+------+\n",
            "|trans_id|sender|receiver|amount|\n",
            "+--------+------+--------+------+\n",
            "|       1|    AA|      BA|120.22|\n",
            "|       2|    BA|      CA|100.55|\n",
            "|       3|    AA|      CA|250.22|\n",
            "|       4|    CA|      AA| 34.55|\n",
            "|       5|    CA|      BA| 55.55|\n",
            "|       6|    ZA|      AA|450.33|\n",
            "|       7|    DA|      ZA|456.55|\n",
            "|       8|    BA|      ZA| 55.78|\n",
            "+--------+------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.sql(\"\"\"\n",
        "with \n",
        "people as \n",
        "  (select distinct a.ppl from \n",
        "      (select  sender as ppl from trans \n",
        "          union all \n",
        "       select  receiver as ppl from trans)a),\n",
        "debit as \n",
        "  (select sender,\n",
        "          sum(amount) as debited \n",
        "    from trans \n",
        "      group by sender ),\n",
        "credit as (\n",
        "      select receiver,\n",
        "            sum(amount) as credited \n",
        "      from trans \n",
        "      group by receiver)\n",
        "\n",
        "select ppl,\n",
        "        round(coalesce(credited,0),2) as credit, \n",
        "        round(coalesce(debited,0),2) as debit,\n",
        "        round((coalesce(credited,0)-coalesce(debited,0)),2) as totalbal from \n",
        "    people peo \n",
        "    left join debit db\n",
        "        on peo.ppl = db.sender\n",
        "    left join credit cr\n",
        "        on peo.ppl = cr.receiver\n",
        "    order by ppl\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "-xXH_9DPnJVX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz-miG1fo_Kb",
        "outputId": "239dfa9d-1d38-466d-ec83-fd69efe95de1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------+--------+\n",
            "|ppl|credit| debit|totalbal|\n",
            "+---+------+------+--------+\n",
            "| AA|484.88|370.44|  114.44|\n",
            "| BA|175.77|156.33|   19.44|\n",
            "| CA|350.77|  90.1|  260.67|\n",
            "| DA|   0.0|456.55| -456.55|\n",
            "| ZA|512.33|450.33|    62.0|\n",
            "+---+------+------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Credit card charges**\n",
        "\n",
        "Find the credit card usage of a customer.\n",
        "  1. If Number of transactions is greater than or equal to 3 and total spend is above Rs.100 or total spend is greater than Rs.150 then that month card charge free, else Rs.5 needs to pay as card charge.\n",
        "  2. In the below scenario, customer needs to pay Rs.5 for 8 months. Only for 4 months he/she is eliglible for concession from above case"
      ],
      "metadata": {
        "id": "rth4qr1FsqWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "credit_card_data = [('2021-01-01',50.00),('2021-01-05',25.00),('2021-01-08',10.00),('2021-01-30',15.00),\\\n",
        "                    ('2021-02-06',45.30),('2021-02-10',65.00),\\\n",
        "                    ('2021-03-01',12.30),('2021-03-10',34.00),('2022-03-24',100.00),\\\n",
        "                    ('2021-04-01',18.90),('2021-04-16',23.00),('2022-04-27',90.00),\\\n",
        "                    ('2021-06-01',45.90),('2021-06-19',65.00),('2022-06-30',78.00),\\\n",
        "                    ('2021-08-01',100.90),('2021-09-19',123.00),\\\n",
        "                    ('2021-12-01',300.00)]\n",
        "credit_schema = ['date','amount']\n",
        "credit_card_df = spark.createDataFrame(credit_card_data,credit_schema)\n",
        "credit_card_df.createOrReplaceTempView('creditcard')"
      ],
      "metadata": {
        "id": "RoGWT_9UqPav"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credit_card_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zribOgRSuLuI",
        "outputId": "4585f0a3-d702-434d-c451-1cccdb5cd99e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+\n",
            "|      date|amount|\n",
            "+----------+------+\n",
            "|2021-01-01|  50.0|\n",
            "|2021-01-05|  25.0|\n",
            "|2021-01-08|  10.0|\n",
            "|2021-01-30|  15.0|\n",
            "|2021-02-06|  45.3|\n",
            "|2021-02-10|  65.0|\n",
            "|2021-03-01|  12.3|\n",
            "|2021-03-10|  34.0|\n",
            "|2022-03-24| 100.0|\n",
            "|2021-04-01|  18.9|\n",
            "|2021-04-16|  23.0|\n",
            "|2022-04-27|  90.0|\n",
            "|2021-06-01|  45.9|\n",
            "|2021-06-19|  65.0|\n",
            "|2022-06-30|  78.0|\n",
            "|2021-08-01| 100.9|\n",
            "|2021-09-19| 123.0|\n",
            "|2021-12-01| 300.0|\n",
            "+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= spark.sql(\"\"\"\n",
        "  select ((12 - b.cnt) * 5) as fee \n",
        "  from (\n",
        "    select count(*) as cnt from (\n",
        "          select \n",
        "              month(date) as mnth, \n",
        "              sum(amount) as mnth_trans,\n",
        "              count(*) as total_trans \n",
        "          from creditcard\n",
        "              group by  month(date)) a\n",
        "    where (a.total_trans >=3 and a.mnth_trans > 100.00) \n",
        "    or a.mnth_trans >= 150.00\n",
        "  ) b\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "WiheL5Divcsx"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NINg83VQv6vY",
        "outputId": "585edbd1-f3b2-4768-c5aa-db7035639fd6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|fee|\n",
            "+---+\n",
            "| 40|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LYhg7Cdj5P9b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}